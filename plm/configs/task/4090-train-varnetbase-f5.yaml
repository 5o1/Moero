seed_everything: 42
trainer:
  accelerator: gpu
  precision: 32
  strategy: ddp
  devices: [0, 3, 4, 5, 6, 7]
  num_nodes: 1
  max_epochs: 1
  log_every_n_steps: 50 # log every n steps during training
  deterministic: false
  use_distributed_sampler: false # Use false because custom VolumeSamplers have been used
  logger: 
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: cmr25
      mode: online
      save_dir: /home/hulabdl/exp
      tags: [cmr25lab, varnetbase, c12, e12, f5, s1, noise_term, nonorm]
      name: varnet
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: validation_loss
        mode: min 
        save_top_k: 1 # -1 to save all checkpoints, 5 to save the top 5 checkpoints
        save_last: True # always save the last checkpoint
    - class_path: plm.callbacks.progbar.MultiColumnRichProgressBar # Configure this term in plm/callbacks/progbar.py
    - class_path: plm.callbacks.MatmulPrecisionCallback
      init_args:
        precision: "high"  # Set to "high" for high precision matmul operations
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor

ckpt_path: null
